{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "path = r'C:\\Users\\Public\\Documents\\HRS\\28.11'\n",
    "beginning_of_name_EL = '\\Feature matrix EL no noise'\n",
    "beginning_of_name_EL_OM = '\\Feature matrix EL+OM no noise'\n",
    "end_of_name = 'peaks.csv'\n",
    "list_of_names = [' 3 ', ' 4 ', ' 5 ', ' no 72_F75 3 ', ' no 72_F75 4 ',  ' no 72_F75 5 ']\n",
    "\n",
    "acc = np.zeros((6,3)) # list of accuracies, shape list_of_names*3\n",
    "f1 = np.zeros((6,3)) # list of f1_scores, shape list_of_names*3\n",
    "for i in range(len(list_of_names)):\n",
    "    data = pd.read_csv(path + beginning_of_name_EL + list_of_names[i] + end_of_name)\n",
    "    data1 = pd.read_csv(path + beginning_of_name_EL_OM + list_of_names[i] + end_of_name)\n",
    "    print(i)\n",
    "    \n",
    "    X = data.drop('target', 1) #full of EL data ~ 900 sequencies\n",
    "    y = data['target']\n",
    "\n",
    "    X1 = data1.drop('target', 1) #full of OM data ~ 200 sequencies\n",
    "    y1 = data1['target']\n",
    "\n",
    "    X2 = data.drop('target', 1)[:np.shape(y1)[0]] #cutted EL data to the size of OM data ~ 200 sequencies\n",
    "    y2 = data['target'][:np.shape(y1)[0]]\n",
    "\n",
    "    (X_train, X_test, y_train, y_test) = train_test_split(X, y, test_size=0.3, stratify=y)\n",
    "    encoder = StandardScaler()\n",
    "    X_train_scaled = encoder.fit_transform(X_train)\n",
    "    X_test_scaled = encoder.fit_transform(X_test)\n",
    "\n",
    "    (X_train_1, X_test_1, y_train_1, y_test_1) = train_test_split(X1, y1, test_size=0.3, stratify=y1)\n",
    "    encoder = StandardScaler()\n",
    "    X_train_scaled_1 = encoder.fit_transform(X_train_1)\n",
    "    X_test_scaled_1 = encoder.fit_transform(X_test_1)\n",
    "\n",
    "    (X_train_2, X_test_2, y_train_2, y_test_2) = train_test_split(X2, y2, test_size=0.3, stratify=y2)\n",
    "    encoder = StandardScaler()\n",
    "    X_train_scaled_2 = encoder.fit_transform(X_train_2)\n",
    "    X_test_scaled_2 = encoder.fit_transform(X_test_2)\n",
    "\n",
    "    model = xgboost.XGBClassifier()\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "\n",
    "    model1 = xgboost.XGBClassifier()\n",
    "    model1.fit(X_train_scaled_1, y_train_1)\n",
    "\n",
    "    model2 = xgboost.XGBClassifier()\n",
    "    model2.fit(X_train_scaled_2, y_train_2)\n",
    "\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    predictions = [round(value) for value in y_pred]\n",
    "\n",
    "    y_pred1 = model1.predict(X_test_scaled_1)\n",
    "    predictions1 = [round(value) for value in y_pred1]\n",
    "\n",
    "    y_pred2 = model2.predict(X_test_scaled_2)\n",
    "    predictions2 = [round(value) for value in y_pred2]\n",
    "    \n",
    "    acc[i][0]= (accuracy_score(y_test, predictions) * 100.0)\n",
    "    acc[i][1]= (accuracy_score(y_test_1, predictions1) * 100.0)\n",
    "    acc[i][2]= (accuracy_score(y_test_2, predictions2) * 100.0)\n",
    "    \n",
    "    f1[i][0]= f1_score(y_test, predictions)\n",
    "    f1[i][1]= f1_score(y_test_1, predictions1)\n",
    "    f1[i][2]= f1_score(y_test_2, predictions2)\n",
    "    \n",
    "#     print(\"Accuracy for EL: %.2f%%\" % (accuracy_score(y_test, predictions) * 100.0))\n",
    "#     print(\"Accuracy for EL and OM: %.2f%%\" % (accuracy_score(y_test_1, predictions1) * 100.0))\n",
    "#     print(\"Accuracy for EL (cutted): %.2f%%\" % (accuracy_score(y_test_2, predictions2) * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 99.6031746 ,  98.71794872,  96.15384615],\n",
       "       [ 97.61904762, 100.        ,  98.71794872],\n",
       "       [ 98.41269841,  94.87179487, 100.        ],\n",
       "       [ 97.43589744,  98.63013699,  98.63013699],\n",
       "       [ 99.57264957,  97.26027397, 100.        ],\n",
       "       [ 97.00854701, 100.        , 100.        ]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 99.20634921,  98.71794872,  97.43589744],\n",
       "       [ 99.6031746 ,  98.71794872,  97.43589744],\n",
       "       [100.        , 100.        , 100.        ],\n",
       "       [ 99.14529915,  97.26027397,  98.63013699],\n",
       "       [ 99.57264957, 100.        ,  95.89041096],\n",
       "       [ 98.71794872,  98.63013699,  97.26027397]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 98.01587302, 100.        ,  97.43589744],\n",
       "       [ 97.61904762, 100.        ,  98.71794872],\n",
       "       [ 99.6031746 , 100.        ,  98.71794872],\n",
       "       [ 96.58119658,  98.63013699,  95.89041096],\n",
       "       [ 97.43589744,  95.89041096,  97.26027397],\n",
       "       [ 98.29059829, 100.        , 100.        ]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.82758621, 1.        , 0.9375    ],\n",
       "       [0.85      , 1.        , 0.97142857],\n",
       "       [0.97142857, 1.        , 0.96969697],\n",
       "       [0.8       , 0.96551724, 0.89655172],\n",
       "       [0.76923077, 0.88      , 0.93333333],\n",
       "       [0.88888889, 1.        , 1.        ]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for EL: 96.43%\n",
      "Accuracy for EL and OM: 100.00%\n",
      "Accuracy for EL (cutted): 97.44%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "path = r'C:\\Users\\Public\\Documents\\HRS\\28.11'\n",
    "data = pd.read_csv(path +'\\Feature matrix EL no noise 5 peaks.csv')\n",
    "data1 = pd.read_csv(path +'\\Feature matrix EL+OM no noise 5 peaks.csv')\n",
    "\n",
    "X = data.drop('target', 1)\n",
    "y = data['target']\n",
    "\n",
    "X1 = data1.drop('target', 1)\n",
    "y1 = data1['target']\n",
    "\n",
    "X2 = data.drop('target', 1)[:np.shape(y1)[0]]\n",
    "y2 = data['target'][:np.shape(y1)[0]]\n",
    "\n",
    "(X_train, X_test, y_train, y_test) = train_test_split(X, y, test_size=0.3, stratify=y)\n",
    "encoder = StandardScaler()\n",
    "X_train_scaled = encoder.fit_transform(X_train)\n",
    "X_test_scaled = encoder.fit_transform(X_test)\n",
    "\n",
    "(X_train_1, X_test_1, y_train_1, y_test_1) = train_test_split(X1, y1, test_size=0.3, stratify=y1)\n",
    "encoder = StandardScaler()\n",
    "X_train_scaled_1 = encoder.fit_transform(X_train_1)\n",
    "X_test_scaled_1 = encoder.fit_transform(X_test_1)\n",
    "\n",
    "(X_train_2, X_test_2, y_train_2, y_test_2) = train_test_split(X2, y2, test_size=0.3, stratify=y2)\n",
    "encoder = StandardScaler()\n",
    "X_train_scaled_2 = encoder.fit_transform(X_train_2)\n",
    "X_test_scaled_2 = encoder.fit_transform(X_test_2)\n",
    "\n",
    "model = xgboost.XGBClassifier()\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "model1 = xgboost.XGBClassifier()\n",
    "model1.fit(X_train_scaled_1, y_train_1)\n",
    "\n",
    "model2 = xgboost.XGBClassifier()\n",
    "model2.fit(X_train_scaled_2, y_train_2)\n",
    "\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "predictions = [round(value) for value in y_pred]\n",
    "\n",
    "y_pred1 = model1.predict(X_test_scaled_1)\n",
    "predictions1 = [round(value) for value in y_pred1]\n",
    "\n",
    "y_pred2 = model2.predict(X_test_scaled_2)\n",
    "predictions2 = [round(value) for value in y_pred2]\n",
    "\n",
    "print(\"Accuracy for EL: %.2f%%\" % (accuracy_score(y_test, predictions) * 100.0))\n",
    "print(\"Accuracy for EL and OM: %.2f%%\" % (accuracy_score(y_test_1, predictions1) * 100.0))\n",
    "print(\"Accuracy for EL (cutted): %.2f%%\" % (accuracy_score(y_test_2, predictions2) * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'C:\\Users\\Public\\Documents\\HRS\\28.11'\n",
    "beginning_of_name_EL = '\\Feature matrix EL no noise'\n",
    "beginning_of_name_EL_OM = '\\Feature matrix EL+OM no noise'\n",
    "end_of_name = 'peaks.csv'\n",
    "list_of_names = [' 3 ', ' 4 ', ' 5 ', ' no 72_F75 3 ', ' no 72_F75 4 ',  ' no 72_F75 5 ']\n",
    "\n",
    "param_grid = {'C': [1,5,10,12,15,17,18,19,20,21,22,23, 25]}\n",
    "cv = 3\n",
    "\n",
    "acc = np.zeros((6,3)) # list of accuracies, shape list_of_names*3\n",
    "f1 = np.zeros((6,3)) # list of f1_scores, shape list_of_names*3\n",
    "\n",
    "for i in range(len(list_of_names)):\n",
    "    data = pd.read_csv(path + beginning_of_name_EL + list_of_names[i] + end_of_name)\n",
    "    data1 = pd.read_csv(path + beginning_of_name_EL_OM + list_of_names[i] + end_of_name)\n",
    "    print(i)\n",
    "    \n",
    "    X = data.drop('target', 1) #full of EL data ~ 900 sequencies\n",
    "    y = data['target']\n",
    "\n",
    "    X1 = data1.drop('target', 1) #full of OM data ~ 200 sequencies\n",
    "    y1 = data1['target']\n",
    "\n",
    "    X2 = data.drop('target', 1)[:np.shape(y1)[0]] #cutted EL data to the size of OM data ~ 200 sequencies\n",
    "    y2 = data['target'][:np.shape(y1)[0]]\n",
    "\n",
    "    (X_train, X_test, y_train, y_test) = train_test_split(X, y, test_size=0.3, stratify=y)\n",
    "    encoder = StandardScaler()\n",
    "    X_train_scaled = encoder.fit_transform(X_train)\n",
    "    X_test_scaled = encoder.fit_transform(X_test)\n",
    "\n",
    "    (X_train_1, X_test_1, y_train_1, y_test_1) = train_test_split(X1, y1, test_size=0.3, stratify=y1)\n",
    "    encoder = StandardScaler()\n",
    "    X_train_scaled_1 = encoder.fit_transform(X_train_1)\n",
    "    X_test_scaled_1 = encoder.fit_transform(X_test_1)\n",
    "\n",
    "    (X_train_2, X_test_2, y_train_2, y_test_2) = train_test_split(X2, y2, test_size=0.3, stratify=y2)\n",
    "    encoder = StandardScaler()\n",
    "    X_train_scaled_2 = encoder.fit_transform(X_train_2)\n",
    "    X_test_scaled_2 = encoder.fit_transform(X_test_2)\n",
    "\n",
    "    model = LogisticRegression(class_weight='balanced')\n",
    "    optimizer = GridSearchCV(model, param_grid, cv=cv)\n",
    "    optimizer.fit(X_train_scaled, y_train)\n",
    "\n",
    "    model1 = LogisticRegression(class_weight='balanced')\n",
    "    optimizer1 = GridSearchCV(model1, param_grid, cv=cv)\n",
    "    optimizer1.fit(X_train_scaled_1, y_train_1)\n",
    "\n",
    "    model2 = LogisticRegression(class_weight='balanced')\n",
    "    optimizer2 = GridSearchCV(model2, param_grid, cv=cv)\n",
    "    optimizer2.fit(X_train_scaled_2, y_train_2)\n",
    "    \n",
    "    acc[i][0]= (accuracy_score(y_test, optimizer.best_estimator_.predict(X_test_scaled)) * 100.0)\n",
    "    acc[i][1]= (accuracy_score(y_test_1, optimizer1.best_estimator_.predict(X_test_scaled_1)) * 100.0)\n",
    "    acc[i][2]= (accuracy_score(y_test_2, optimizer2.best_estimator_.predict(X_test_scaled_2)) * 100.0)\n",
    "    \n",
    "    f1[i][0]= f1_score(y_test, optimizer.best_estimator_.predict(X_test_scaled), average ='weighted')\n",
    "    f1[i][1]= f1_score(y_test_1, optimizer1.best_estimator_.predict(X_test_scaled_1), average ='weighted')\n",
    "    f1[i][2]= f1_score(y_test_2, optimizer2.best_estimator_.predict(X_test_scaled_2), average ='weighted')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
