{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "from statsmodels.stats.weightstats import _zconfint_generic, _tconfint_generic\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "from IPython import display\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 3 peaks.csv\n",
      "(1098, 15) (1098,)\n",
      "(296, 30) (296,)\n",
      "SVC model EL f1: mean 0.875, std 0.024\n",
      "SVC model EL+OM f1: mean 0.866, std 0.066\n",
      "SVC model EL mean f1 95%% confidence interval: (0.8578810527940206, 0.8926666813308279)\n",
      "SVC model EL+OM mean f1 95%% confidence interval: (0.8189150341940713, 0.9137961900243831)\n",
      " 4 peaks.csv\n",
      "(1098, 19) (1098,)\n",
      "(296, 38) (296,)\n",
      "SVC model EL f1: mean 0.900, std 0.019\n",
      "SVC model EL+OM f1: mean 0.869, std 0.047\n",
      "SVC model EL mean f1 95%% confidence interval: (0.8863208988849325, 0.9137029988701408)\n",
      "SVC model EL+OM mean f1 95%% confidence interval: (0.8355864591953184, 0.903205259838336)\n",
      " 5 peaks.csv\n",
      "(1098, 23) (1098,)\n",
      "(296, 46) (296,)\n",
      "SVC model EL f1: mean 0.914, std 0.026\n",
      "SVC model EL+OM f1: mean 0.884, std 0.044\n",
      "SVC model EL mean f1 95%% confidence interval: (0.8953302120316042, 0.9323551439728859)\n",
      "SVC model EL+OM mean f1 95%% confidence interval: (0.8525864662458317, 0.9152457220134652)\n"
     ]
    }
   ],
   "source": [
    "path = r'C:\\Users\\Public\\Documents\\HRS\\Features new'\n",
    "beginning_of_name_EL = '\\Feature matrix EL no noise'\n",
    "beginning_of_name_EL_OM = '\\Feature matrix EL+OM no noise'\n",
    "end_of_name = 'peaks.csv'\n",
    "list_of_names = [' 3 ', ' 4 ', ' 5 ']\n",
    "\n",
    "f1 = np.zeros((3,2)) # list of f1_scores, shape list_of_names*3\n",
    "acc = np.zeros((3,2)) # list of accuracies, shape list_of_names*3\n",
    "f1_left_confint = np.zeros((3,2))\n",
    "f1_right_confint = np.zeros((3,2))\n",
    "\n",
    "for i in range(len(list_of_names)):\n",
    "    data = pd.read_csv(path + beginning_of_name_EL + list_of_names[i] + end_of_name, index_col=0)\n",
    "    data.drop(['Label for OM and EL'], axis=1, inplace=True)\n",
    "    data1 = pd.read_csv(path + beginning_of_name_EL_OM + list_of_names[i] + end_of_name, index_col=0)\n",
    "    print(list_of_names[i] + end_of_name)\n",
    "    \n",
    "    X = data.drop('target', axis=1) #full of EL data ~ 900 sequencies\n",
    "    y = data['target']\n",
    "\n",
    "    X1 = data1.drop('target', axis=1) #full of EL+OM data ~ 200 sequencies\n",
    "    y1 = data1['target']\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    \n",
    "    X = scaler.fit_transform(X)\n",
    "    X1 = scaler.fit_transform(X1)\n",
    "     \n",
    "\n",
    "    (X_train, X_test, y_train, y_test) = train_test_split(X, y, test_size=0.3, stratify=y)\n",
    "\n",
    "    (X1_train, X1_test, y1_train, y1_test) = train_test_split(X1, y1,\\\n",
    "                                                                  test_size=0.3, stratify=y1)\n",
    "    \n",
    "    X_resampled, y_resampled = SMOTE().fit_resample(X_train, y_train)\n",
    "    print(X_resampled.shape, y_resampled.shape)\n",
    "    X1_resampled, y1_resampled = SMOTE().fit_resample(X1_train, y1_train)\n",
    "    print(X1_resampled.shape, y1_resampled.shape)\n",
    "\n",
    "    \n",
    "#     parameters = {'kernel':('linear', 'rbf'), 'C':[1, 2, 5, 7, 10]}\n",
    "\n",
    "\n",
    "    clf = SVC(kernel='rbf', C=1.0, gamma='scale', class_weight='balanced')\n",
    "    clf.fit(X_resampled, y_resampled)\n",
    "    \n",
    "    clf1 = SVC(kernel='rbf', C=1.0, gamma='scale', class_weight='balanced') \n",
    "    clf1.fit(X1_resampled, y1_resampled)\n",
    "    \n",
    "    y_pred = clf.predict(X_test)\n",
    "    y1_pred = clf1.predict(X1_test)\n",
    "    \n",
    "    acc[i][0]= (accuracy_score(y_test, y_pred) * 100.0)\n",
    "    acc[i][1]= (accuracy_score(y1_test, y1_pred) * 100.0)\n",
    "    \n",
    "    f1[i][0]= f1_score(y_test, y_pred)\n",
    "    f1[i][1]= f1_score(y1_test, y1_pred)\n",
    "\n",
    "    f1score = cross_val_score(clf, X_resampled, y_resampled, scoring='f1', cv=10)\n",
    "    f1score1 = cross_val_score(clf, X1_resampled, y1_resampled, scoring='f1', cv=10)\n",
    "\n",
    "    mean = f1score.mean()\n",
    "    mean1 = f1score1.mean()\n",
    "    \n",
    "    print(\"SVC model EL f1: mean %.3f, std %.3f\" % (f1score.mean(), f1score.std(ddof=1)))\n",
    "    print(\"SVC model EL+OM f1: mean %.3f, std %.3f\" % (f1score1.mean(), f1score1.std(ddof=1)))\n",
    "    \n",
    "    mean_std = f1score.std(ddof=1)/np.sqrt(len(f1score))\n",
    "    mean_std1 = f1score1.std(ddof=1)/np.sqrt(len(f1score1))\n",
    "    \n",
    "    tconf = _tconfint_generic(mean, mean_std, len(f1score) - 1, 0.05, 'two-sided')\n",
    "    tconf1 = _tconfint_generic(mean1, mean_std1, len(f1score1) - 1, 0.05, 'two-sided')\n",
    "\n",
    "    print(\"SVC model EL mean f1 95%% confidence interval:\", tconf)\n",
    "    print(\"SVC model EL+OM mean f1 95%% confidence interval:\", tconf1)\n",
    "    \n",
    "#     optimizer = GridSearchCV(clf, parameters, cv=10, scoring='f1')\n",
    "#     optimizer.fit(X_train, y_train) \n",
    "#     print(optimizer.best_score_, optimizer.best_params_)\n",
    "    \n",
    "    \n",
    "\n",
    "#     optimizer1 = GridSearchCV(clf, parameters, cv=10, scoring='f1')\n",
    "#     optimizer1.fit(X1_train, y1_train) \n",
    "#     print(optimizer1.best_score_, optimizer1.best_params_)\n",
    "\n",
    "\n",
    "#     y_pred = optimizer.best_estimator_.predict(X_test)\n",
    "#     y_pred1 = optimizer1.best_estimator_.predict(X1_test)\n",
    "\n",
    "#     f1[i][0]= f1_score(y_test, y_pred)\n",
    "#     f1[i][1]= f1_score(y1_test, y_pred1)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.10810811, 0.61904762],\n",
       "       [0.17857143, 0.48888889],\n",
       "       [0.2       , 0.4       ]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[73.80952381, 79.48717949],\n",
       "       [81.74603175, 70.51282051],\n",
       "       [84.12698413, 69.23076923]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
