{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import xgboost\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from statsmodels.stats.weightstats import _zconfint_generic, _tconfint_generic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "path = r'C:\\Users\\Public\\Documents\\HRS\\28.11'\n",
    "beginning_of_name_EL = '\\Feature matrix EL no noise'\n",
    "beginning_of_name_EL_OM = '\\Feature matrix EL+OM no noise'\n",
    "end_of_name = 'peaks.csv'\n",
    "list_of_names = [' 3 ', ' 4 ', ' 5 ']\n",
    "\n",
    "acc = np.zeros((3,3)) # list of accuracies, shape list_of_names*3\n",
    "f1 = np.zeros((3,3)) # list of f1_scores, shape list_of_names*3\n",
    "f1_left_confint = np.zeros((3,3))\n",
    "f1_right_confint = np.zeros((3,3))\n",
    "\n",
    "for i in range(len(list_of_names)):\n",
    "    data = pd.read_csv(path + beginning_of_name_EL + list_of_names[i] + end_of_name, index_col=0)\n",
    "    data1 = pd.read_csv(path + beginning_of_name_EL_OM + list_of_names[i] + end_of_name, index_col=0)\n",
    "    data.drop(['Label for OM and EL'], axis=1, inplace=True)\n",
    "    print(i)\n",
    "    \n",
    "    X = data.drop('target', 1) #full of EL data ~ 900 sequencies\n",
    "    y = data['target']\n",
    "\n",
    "    X1 = data1.drop('target', 1) #full of OM data ~ 200 sequencies\n",
    "    y1 = data1['target']\n",
    "    \n",
    "    target=data1['target']\n",
    "    data2 = data1.iloc[:,:int((data1.shape[1]-1)/2)]\n",
    "    data2 = pd.concat([data2, target], axis=1)\n",
    "    \n",
    "    X2 = data2.drop('target', 1) #cutted EL data to the size of OM data ~ 200 sequencies\n",
    "    y2 = data2['target']\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    \n",
    "    X = scaler.fit_transform(X)\n",
    "    X1 = scaler.fit_transform(X1)\n",
    "    X2 = scaler.fit_transform(X2)\n",
    "    \n",
    "    X_resampled, y_resampled = SMOTE().fit_resample(X, y)\n",
    "    X1_resampled, y1_resampled = SMOTE().fit_resample(X1, y1)\n",
    "    X2_resampled, y2_resampled = SMOTE().fit_resample(X2, y2)\n",
    "    \n",
    "    (X_train, X_test, y_train, y_test) = train_test_split(X_resampled, y_resampled, test_size=0.3, stratify=y_resampled)\n",
    "\n",
    "    (X_train_1, X_test_1, y_train_1, y_test_1) = train_test_split(X1_resampled, y1_resampled, test_size=0.3, stratify=y1_resampled)\n",
    "\n",
    "    (X_train_2, X_test_2, y_train_2, y_test_2) = train_test_split(X2_resampled, y2_resampled, test_size=0.3, stratify=y2_resampled)\n",
    "    \n",
    "    model = RandomForestClassifier(n_estimators = 1000, n_jobs = -1)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    model1 = RandomForestClassifier(n_estimators = 1000, n_jobs = -1)\n",
    "    model1.fit(X_train_1, y_train_1)\n",
    "\n",
    "    model2 = RandomForestClassifier(n_estimators = 1000, n_jobs = -1)\n",
    "    model2.fit(X_train_2, y_train_2)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred1 = model1.predict(X_test_1)\n",
    "    y_pred2 = model2.predict(X_test_2)\n",
    "    \n",
    "    acc[i][0]= (accuracy_score(y_test, y_pred) * 100.0)\n",
    "    acc[i][1]= (accuracy_score(y_test_1, y_pred1) * 100.0)\n",
    "    acc[i][2]= (accuracy_score(y_test_2, y_pred2) * 100.0)\n",
    "    \n",
    "    f1[i][0]= f1_score(y_test, y_pred)\n",
    "    f1[i][1]= f1_score(y_test_1, y_pred1)\n",
    "    f1[i][2]= f1_score(y_test_2, y_pred2)\n",
    "    \n",
    "    f1_scores = cross_val_score(model, X_resampled, y_resampled, scoring = 'f1',  cv = 20)\n",
    "    f1_scores_1 = cross_val_score(model1, X1_resampled, y1_resampled, scoring = 'f1',  cv = 20)\n",
    "    f1_scores_2 = cross_val_score(model2, X2_resampled, y2_resampled, scoring = 'f1',  cv = 20)\n",
    "    \n",
    "    mean = f1_scores.mean()\n",
    "    mean1 = f1_scores_1.mean()\n",
    "    mean2 = f1_scores_2.mean()\n",
    "    \n",
    "    mean_std = f1_scores.std(ddof=1)/np.sqrt(len(f1_scores))\n",
    "    mean_std1 = f1_scores_1.std(ddof=1)/np.sqrt(len(f1_scores_1))\n",
    "    mean_std2 = f1_scores_2.std(ddof=1)/np.sqrt(len(f1_scores_2))\n",
    "    \n",
    "    tconf=_tconfint_generic(mean, mean_std,len(f1_scores) - 1,0.05, 'two-sided')\n",
    "    tconf_1=_tconfint_generic(mean1, mean_std1,len(f1_scores_1) - 1,0.05, 'two-sided')\n",
    "    tconf_2=_tconfint_generic(mean2, mean_std2,len(f1_scores_2) - 1,0.05, 'two-sided')\n",
    "    \n",
    "    f1_left_confint[i][0] = tconf[0]\n",
    "    f1_left_confint[i][1] = tconf_1[0]\n",
    "    f1_left_confint[i][2] = tconf_2[0]\n",
    "    \n",
    "    f1_right_confint[i][0] = tconf[1]\n",
    "    f1_right_confint[i][1] = tconf_1[1]\n",
    "    f1_right_confint[i][2] = tconf_2[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.93361884, 0.87878788, 0.81751825],\n",
       "       [0.96016771, 0.88059701, 0.89552239],\n",
       "       [0.98319328, 0.921875  , 0.896     ]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[93.41825902, 87.4015748 , 80.31496063],\n",
       "       [95.96602972, 87.4015748 , 88.97637795],\n",
       "       [98.3014862 , 92.12598425, 89.76377953]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.91470849, 0.80858053, 0.76934238],\n",
       "       [0.93551329, 0.82602774, 0.7820426 ],\n",
       "       [0.95752485, 0.79771354, 0.8167237 ]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_left_confint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.95718395, 0.92878439, 0.89066431],\n",
       "       [0.97247742, 0.94333539, 0.89832107],\n",
       "       [0.980758  , 0.93348773, 0.90188851]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_right_confint"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
